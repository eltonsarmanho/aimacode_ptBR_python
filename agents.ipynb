{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentes Inteligentes #\n",
    "\n",
    "Este notebook serve como material de apoio para os tópicos abordados no **Capítulo 2 - Agentes Inteligentes** do livro *Artificial Intelligence: A Modern Approach*. Este notebook utiliza implementações do módulo [agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py). Vamos começar importando tudo do módulo de agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pode ser necessário instalar algumas libs\n",
    "#!pip install ipythonblocks\n",
    "#!pip install qpsolvers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import *\n",
    "from notebook import psource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTENTS\n",
    "\n",
    "* Overview\n",
    "* Agent\n",
    "* Environment\n",
    "* Simple Agent and Environment\n",
    "* Agents in a 2-D Environment\n",
    "* Wumpus Environment\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "Um agente, conforme definido em 2.1, é qualquer coisa que possa perceber seu ambiente através de sensores e agir sobre esse ambiente através de atuadores, com base em seu programa de agente. Isso pode ser um cachorro, um robô ou até mesmo você. Contanto que você possa perceber o ambiente e agir sobre ele, você é um agente. Este notebook explicará como implementar um agente simples, criar um ambiente e implementar um programa que ajude o agente a agir sobre o ambiente com base em suas percepções.\n",
    "\n",
    "## AGENT\n",
    "\n",
    "Let us now see how we define an agent. Run the next cell to see how `Agent` is defined in agents module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `Agent` possui dois métodos:\n",
    "* `__init__(self, program=None)`: O construtor define vários atributos do Agente. Estes incluem:\n",
    "\n",
    "    * `alive`: que acompanha se o agente está vivo ou não\n",
    "    \n",
    "    * `bump`:  que rastreia se o agente colide com uma borda do ambiente (por exemplo, uma parede em um parque)\n",
    "    \n",
    "    * `holding`: que é uma lista contendo os Things (objetos) que um agente está segurando\n",
    "    \n",
    "    * `performance`:que avalia as métricas de desempenho do agente\n",
    "    \n",
    "    * `program`: que é o programa do agente e mapeia as percepções do agente para ações no ambiente. Se nenhuma implementação for fornecida, o padrão é solicitar ao usuário que forneça ações para cada percepção.\n",
    "    \n",
    "* `can_grab(self, thing)`:  É usado quando um ambiente contém objetos que um agente pode pegar e carregar. Por padrão, um agente não pode carregar nada.\n",
    "\n",
    "\n",
    "## ENVIRONMENT\n",
    "Now, let us see how environments are defined. Running the next cell will display an implementation of the abstract `Environment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(Environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `Environment` possui muitos métodos! Mas a maioria deles é incrivelmente simples, então vamos ver os que utilizaremos neste notebook.\n",
    "\n",
    "* `thing_classes(self)`: Retorna um array estático de sub-classes de `Thing` que determinam quais coisas são permitidas no ambiente e quais não são.\n",
    "\n",
    "* `add_thing(self, thing, location=None)`: Adiciona uma coisa ao ambiente em uma determinada localização.\n",
    "\n",
    "* `run(self, steps)`: Executa um ambiente com o agente nele por um determinado número de passos.\n",
    "\n",
    "* `is_done(self)`: Retorna verdadeiro se o objetivo do agente e do ambiente foi concluído.\n",
    "\n",
    "As próximas duas funções devem ser implementadas por cada subclasse de `Environment` para que o agente receba percepções e execute ações.\n",
    "\n",
    "* `percept(self, agent)`: Dado um agente, este método retorna uma lista de percepções que o agente observa no momento atual.\n",
    "\n",
    "* `execute_action(self, agent, action)`: O ambiente reage a uma ação realizada por um determinado agente. As mudanças podem resultar em o agente experimentar novas percepções ou outros elementos reagirem à entrada do agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENTE SIMPLES E AMBIENTE\n",
    "\n",
    "\"Vamos começar utilizando a classe `Agent` para criar nosso primeiro agente - um cachorro cego (a blind dog).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlindDog(Agent):\n",
    "    def eat(self, thing):\n",
    "        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "            \n",
    "    def drink(self, thing):\n",
    "        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "\n",
    "dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro: Não foi possível encontrar um programa válido para BlindDog, voltando ao padrão.\n",
    "O que acabamos de fazer é criar um cachorro que só pode sentir o que está em sua localização (já que ele é cego) e pode comer ou beber. Vamos ver se ele está vivo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif)\n",
    "Este é o nosso cachorro. Vamos considerar que ele está com fome e precisa sair em busca de comida. Para que ele faça isso, precisamos dar a ele um **programa**. Mas antes disso, vamos criar um **parque** para o nosso cachorro brincar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiente (ENVIRONMENT) - Parque (Park)\n",
    "\n",
    "Um parque é um exemplo de ambiente porque nosso cachorro pode percebê-lo e agir sobre ele. A classe <b>Environment</b> é uma classe abstrata, então teremos que criar nossa própria subclasse a partir dela antes de podermos usá-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food(Thing):\n",
    "    pass\n",
    "\n",
    "class Water(Thing):\n",
    "    pass\n",
    "\n",
    "class Park(Environment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "\n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROGRAM - BlindDog\n",
    "Agora que temos uma classe <b>Park</b>, reimplementamos nosso <b>BlindDog</b> para que ele possa se mover para baixo e comer comida ou beber água apenas se estiver presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlindDog(Agent):\n",
    "    location = 1\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é hora de implementar um módulo de <b>program</b> para o nosso cachorro. Um programa controla como o cachorro age sobre seu ambiente. Nosso programa será bem simples, como mostrado na tabela abaixo.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move down</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program(percepts):\n",
    "    '''Returns an action based on the dog's percepts'''\n",
    "    for p in percepts:\n",
    "        if isinstance(p, Food):\n",
    "            return 'eat'\n",
    "        elif isinstance(p, Water):\n",
    "            return 'drink'\n",
    "    return 'move down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos rodar nossa simulação criando um parque com comida, água e o nosso cachorro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park()\n",
    "dog = BlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, 1)\n",
    "park.add_thing(dogfood, 5)\n",
    "park.add_thing(water, 7)\n",
    "\n",
    "park.run(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dog moved from location 1 to 4, over 4 steps, and ate food at location 5 in the 5th step.\n",
    "\n",
    "Let's continue this simulation for 5 more steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Note how the simulation stopped after the dog drank the water - exhausting all the food and water ends our simulation, as we had defined before. Let's add some more water and see if our dog can reach it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.add_thing(water, 15)\n",
    "park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, aprendemos a implementar um agente, seu programa e um ambiente no qual ele atua. No entanto, este foi um caso muito simples. Vamos tentar adicionar complexidade criando um ambiente bidimensional!\n",
    "\n",
    "## AGENTES EM UM AMBIENTE 2D\n",
    "\n",
    "Para evitar ler tantos logs sobre o que nosso cachorro fez, vamos adicionar um pouco de gráficos enquanto tornamos nosso Parque 2D. Para isso, precisaremos torná-lo uma subclasse de <b>GraphicEnvironment</b> em vez de Environment. Parques implementados como subclasses da classe <b>GraphicEnvironment</b> adicionam essas propriedades extras:\n",
    "\n",
    "- Nosso parque é indexado no 4º quadrante do plano X-Y.\n",
    "- Toda vez que criamos um parque como subclasse de <b>GraphicEnvironment</b>, precisamos definir as cores de todos os itens que planejamos colocar no parque. As cores são definidas no típico [<b>formato RGB digital de 8 bits</b>](https://en.wikipedia.org/wiki/RGB_color_model#Numeric_representations), comum na web.\n",
    "- Cercas são adicionadas automaticamente a todos os parques para que nosso cachorro não saia dos limites do parque — simplesmente não é seguro para cachorros cegos ficarem fora do parque sozinhos! <b>GraphicEnvironment</b> fornece a função `is_inbounds` para verificar se nosso cachorro tenta sair do parque.\n",
    "\n",
    "Primeiro, vamos tentar atualizar nosso ambiente `Park` unidimensional apenas substituindo sua superclasse por `GraphicEnvironment`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Park2D(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "class BlindDog(Agent):\n",
    "    location = [0,1] # change location to a 2d value\n",
    "    direction = Direction(\"down\") # variable to store the direction our dog is facing\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location[1] += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos testar este novo parque com o mesmo cachorro, comida e água. Colorimos nosso cachorro com vermelho e marcamos a comida e a água com laranja e azul, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,20, color={'BlindDog': (200,0,0), 'Food': (230, 115, 40),'Water': (0, 200, 200)}) \n",
    "# park largura = 5 (width) e altura = 20 (height)\n",
    "dog = BlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,1])\n",
    "park.add_thing(dogfood, [0,5])\n",
    "park.add_thing(water, [0,7])\n",
    "morewater = Water()\n",
    "park.add_thing(morewater, [0,15])\n",
    "print(\"O BlindDog começa em (0,1) voltado para baixo, vamos ver se ele consegue encontrar alguma comida!\")\n",
    "park.run(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos imediatamente que o código funciona, mas nosso cachorro cego **não faz uso** do espaço bidimensional disponível para ele. Vamos deixar nosso cachorro mais enérgico para que ele vire e avance, em vez de sempre se mover para baixo. Ao fazer isso, também precisaremos fazer algumas alterações em nosso ambiente para lidar com esse movimento extra.\n",
    "\n",
    "### PROGRAMA - EnergeticBlindDog\n",
    "\n",
    "Vamos fazer nosso cachorro virar ou avançar aleatoriamente — exceto quando ele estiver na borda do nosso parque — nesse caso, faremos ele mudar de direção explicitamente, virando para evitar tentar sair do parque. No entanto, nosso cachorro é cego, então ele não saberia para que lado virar — ele teria que tentar aleatoriamente.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percepto:</b> </td>\n",
    "        <td>Sente Comida </td>\n",
    "        <td>Sente Água</td>\n",
    "        <td>Não Sente Nada</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Ação:</b> </td>\n",
    "       <td>comer</td>\n",
    "       <td>beber</td>\n",
    "       <td>\n",
    "       <table>\n",
    "           <tr>\n",
    "               <td><b>Lembrar de estar na borda:</b></td>\n",
    "               <td>Na Borda</td>\n",
    "               <td>Não na Borda</td>\n",
    "           </tr>\n",
    "           <tr>\n",
    "               <td><b>Ação:</b></td>\n",
    "               <td>Virar à Esquerda / Virar à Direita <br> (50% - 50% de chance)</td>\n",
    "               <td>Virar à Esquerda / Virar à Direita / Avançar <br> (25% - 25% - 50% de chance)</td>\n",
    "           </tr>\n",
    "       </table>\n",
    "       </td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class EnergeticBlindDog(Agent):\n",
    "    location = [0,1]\n",
    "    direction = Direction(\"down\")\n",
    "    \n",
    "    def moveforward(self, success=True):\n",
    "        '''moveforward possible only if success (i.e. valid destination location). \n",
    "           Avançar só é possível se for bem-sucedido (ou seja, se o destino for uma localização válida)'''\n",
    "        if not success:\n",
    "            return\n",
    "        if self.direction.direction == Direction.R:\n",
    "            self.location[0] += 1\n",
    "        elif self.direction.direction == Direction.L:\n",
    "            self.location[0] -= 1\n",
    "        elif self.direction.direction == Direction.D:\n",
    "            self.location[1] += 1\n",
    "        elif self.direction.direction == Direction.U:\n",
    "            self.location[1] -= 1\n",
    "    \n",
    "    def turn(self, d):\n",
    "        self.direction = self.direction + d\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "def program(percepts):\n",
    "    '''Returns an action based on it's percepts'''\n",
    "        \n",
    "    for p in percepts: # first eat or drink - you're a dog!\n",
    "        if isinstance(p, Food):\n",
    "            return 'eat'\n",
    "        elif isinstance(p, Water):\n",
    "            return 'drink'\n",
    "        if isinstance(p,Bump): # então verifique se você está na borda e precisa virar\n",
    "            # Bump: rastreia se o agente colide com uma borda do ambiente\n",
    "            turn = False\n",
    "            choice = random.choice((1,2));\n",
    "        else:\n",
    "            choice = random.choice((1,2,3,4)) # 1-right, 2-left, others-forward\n",
    "    if choice == 1:\n",
    "        return 'turnright'\n",
    "    elif choice == 2:\n",
    "        return 'turnleft'\n",
    "    else:\n",
    "        return 'moveforward'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMBIENTE (ENVIRONMENT) - Park2D\n",
    "\n",
    "Também precisamos modificar nosso parque adequadamente, para ser capaz de lidar com todas as novas ações que nosso cachorro deseja executar. Além disso, precisaremos impedir que nosso cachorro se mova para locais além dos limites do parque — simplesmente não é seguro para cachorros cegos ficarem fora do parque sozinhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Park2D(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        loc = copy.deepcopy(agent.location) # find out the target location (descobrir a localização de destino)\n",
    "        #Check if agent is about to bump into a wall (Verifique se o agente está prestes a esbarrar em uma parede)\n",
    "        if agent.direction.direction == Direction.R:\n",
    "            loc[0] += 1\n",
    "        elif agent.direction.direction == Direction.L:\n",
    "            loc[0] -= 1\n",
    "        elif agent.direction.direction == Direction.D:\n",
    "            loc[1] += 1\n",
    "        elif agent.direction.direction == Direction.U:\n",
    "            loc[1] -= 1\n",
    "        if not self.is_inbounds(loc):# Verifica se nosso cachorro tenta sair do parque.\n",
    "            things.append(Bump())\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == 'turnright':\n",
    "            print('{} decidiu ir para {} na localização: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.turn(Direction.R)\n",
    "        elif action == 'turnleft':\n",
    "            print('{} decidiu ir para {} na localização: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.turn(Direction.L)\n",
    "        elif action == 'moveforward':\n",
    "            print('{} decidiu mover {} direcionado para a localização: {}'.format(str(agent)[1:-1], agent.direction.direction, agent.location))\n",
    "            agent.moveforward()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]):\n",
    "                    print('{} comeu {} na localização: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0])\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]):\n",
    "                    print('{} bebeu {} na localização: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0])\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que nosso parque está pronto para o movimento 2D do nosso cachorro, vamos testá-lo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,5, color={'EnergeticBlindDog': (200,0,0), 'Water': (0, 200, 200), 'Food': (230, 115, 40)})\n",
    "dog = EnergeticBlindDog(program)\n",
    "dogfood = Food()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,0])\n",
    "park.add_thing(dogfood, [1,2])\n",
    "park.add_thing(water, [0,1])\n",
    "morewater = Water()\n",
    "morefood = Food()\n",
    "park.add_thing(morewater, [2,4])\n",
    "park.add_thing(morefood, [4,3])\n",
    "print(\"O cachorro começou em [0,0], voltado para baixo. Vamos ver se ele encontrou alguma comida ou água!\")\n",
    "park.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadrado vermelho é o AGENTE caçando comida e agua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula Prática: Implementando um Agente Inteligente em Python\n",
    "\n",
    "### Objetivo\n",
    "Nesta aula, vamos implementar um **agente inteligente** que aprende a interagir com um ambiente usando a biblioteca `gym`. O ambiente escolhido será o **CartPole**, um problema clássico de controle onde o objetivo é equilibrar uma vara em um carrinho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisitos\n",
    "1. **Python 3** instalado.\n",
    "2. Bibliotecas necessárias:\n",
    "   - `gym`: Para criar o ambiente.\n",
    "   - `numpy`: Para cálculos numéricos.\n",
    "   - `matplotlib`: Para visualização dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy in /home/eltonss/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/eltonss/anaconda3/lib/python3.11/site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/eltonss/anaconda3/lib/python3.11/site-packages (from gymnasium) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: Importando as Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Criando o Ambiente\n",
    "Vamos criar o ambiente **CartPole**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **O que é o CartPole?**\n",
    "  - O ambiente consiste em um carrinho que pode se mover para a esquerda ou direita.\n",
    "  - Uma vara é presa ao carrinho, e o objetivo é equilibrar a vara por quanto tempo for possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loop de Interação com o Ambiente\n",
    "O agente segue uma política simples (aleatória) para interagir com o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódio 1: Pontuação = 20.0\n",
      "Episódio 2: Pontuação = 13.0\n",
      "Episódio 3: Pontuação = 35.0\n",
      "Episódio 4: Pontuação = 46.0\n",
      "Episódio 5: Pontuação = 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eltonss/anaconda3/lib/python3.11/site-packages/gymnasium/envs/classic_control/cartpole.py:250: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inicializando variáveis\n",
    "num_episodios = 5\n",
    "\n",
    "for episodio in range(num_episodios):\n",
    "    estado = env.reset()  # Reinicia o ambiente\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()  # Renderiza o ambiente\n",
    "        \n",
    "        # Escolha da ação (aleatória neste exemplo)\n",
    "        acao = env.action_space.sample()\n",
    "        \n",
    "        # Executa a ação\n",
    "        novo_estado, recompensa, done, _, _ = env.step(acao)\n",
    "        \n",
    "        # Acumula a pontuação\n",
    "        score += recompensa\n",
    "\n",
    "    print(f\"Episódio {episodio + 1}: Pontuação = {score}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensão: Introduzindo Inteligência ao Agente\n",
    "Podemos adicionar um agente mais avançado usando técnicas de aprendizado por reforço. Aqui, implementamos uma política simples que ajusta suas ações com base no estado percebido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódio 1: Pontuação = 12.0\n",
      "Episódio 2: Pontuação = 12.0\n",
      "Episódio 3: Pontuação = 26.0\n",
      "Episódio 4: Pontuação = 16.0\n",
      "Episódio 5: Pontuação = 13.0\n"
     ]
    }
   ],
   "source": [
    "class AgenteSimples:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def escolher_acao(self, estado):\n",
    "        # Exemplo: Política baseada no estado (aqui, aleatória para simplicidade)\n",
    "        return self.action_space.sample()\n",
    "\n",
    "# Criando o agente\n",
    "agente = AgenteSimples(env.action_space)\n",
    "\n",
    "# Reexecutando o loop com o agente\n",
    "for episodio in range(num_episodios):\n",
    "    estado = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        acao = agente.escolher_acao(estado)\n",
    "        novo_estado, recompensa, done, _, _ = env.step(acao)\n",
    "        score += recompensa\n",
    "\n",
    "    print(f\"Episódio {episodio + 1}: Pontuação = {score}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do Ambiente Aspirador de Pó com Gymnasium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição\n",
    "O ambiente consiste em:\n",
    "- Duas salas (esquerda e direita) que podem estar limpas ou sujas.\n",
    "- O agente pode:\n",
    "  - Mover-se entre as salas.\n",
    "  - Limpar a sala atual.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código do Ambiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class AspiradorEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(AspiradorEnv, self).__init__()\n",
    "        # Espaço de ação: 0 = direita, 1 = esquerda, 2 = limpar\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        # Espaço de observação: [estado da sala esquerda, estado da sala direita, posição do agente]\n",
    "        self.observation_space = spaces.MultiDiscrete([2, 2, 2])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Estado inicial: ambas as salas sujas e agente na sala esquerda\n",
    "        self.state = np.array([1, 1, 0])\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        recompensa = 0\n",
    "\n",
    "        # Mover para a direita\n",
    "        if action == 0 and self.state[2] == 0:\n",
    "            self.state[2] = 1\n",
    "        # Mover para a esquerda\n",
    "        elif action == 1 and self.state[2] == 1:\n",
    "            self.state[2] = 0\n",
    "        # Limpar a sala atual\n",
    "        elif action == 2:\n",
    "            if self.state[self.state[2]] == 1:\n",
    "                self.state[self.state[2]] = 0\n",
    "                recompensa = 1\n",
    "\n",
    "        # O episódio termina quando ambas as salas estão limpas\n",
    "        done = np.all(self.state[:2] == 0)\n",
    "\n",
    "        return self.state, recompensa, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        sala = [\"Limpo\" if x == 0 else \"Sujo\" for x in self.state[:2]]\n",
    "        posicao = \"Esquerda\" if self.state[2] == 0 else \"Direita\"\n",
    "        print(f\"Sala Esquerda: {sala[0]}, Sala Direita: {sala[1]}, Posição do Agente: {posicao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do Agente\n",
    "\n",
    "### Código do Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenteSimples:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def escolher_acao(self, estado):\n",
    "        # Se a sala atual estiver suja, limpa\n",
    "        if estado[estado[2]] == 1:\n",
    "            return 2  # Limpar\n",
    "        # Caso contrário, move para a próxima sala\n",
    "        elif estado[2] == 0:\n",
    "            return 0  # Mover para a direita\n",
    "        else:\n",
    "            return 1  # Mover para a esquerda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulação\n",
    "\n",
    "### Código da Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episódio 1:\n",
      "Sala Esquerda: Sujo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 2, Recompensa: 1\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 0, Recompensa: 0\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Direita\n",
      "Ação: 2, Recompensa: 1\n",
      "Episódio concluído em 3 passos!\n",
      "\n",
      "Episódio 2:\n",
      "Sala Esquerda: Sujo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 2, Recompensa: 1\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 0, Recompensa: 0\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Direita\n",
      "Ação: 2, Recompensa: 1\n",
      "Episódio concluído em 3 passos!\n",
      "\n",
      "Episódio 3:\n",
      "Sala Esquerda: Sujo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 2, Recompensa: 1\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 0, Recompensa: 0\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Direita\n",
      "Ação: 2, Recompensa: 1\n",
      "Episódio concluído em 3 passos!\n",
      "\n",
      "Episódio 4:\n",
      "Sala Esquerda: Sujo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 2, Recompensa: 1\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 0, Recompensa: 0\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Direita\n",
      "Ação: 2, Recompensa: 1\n",
      "Episódio concluído em 3 passos!\n",
      "\n",
      "Episódio 5:\n",
      "Sala Esquerda: Sujo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 2, Recompensa: 1\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Esquerda\n",
      "Ação: 0, Recompensa: 0\n",
      "Sala Esquerda: Limpo, Sala Direita: Sujo, Posição do Agente: Direita\n",
      "Ação: 2, Recompensa: 1\n",
      "Episódio concluído em 3 passos!\n"
     ]
    }
   ],
   "source": [
    "# Inicializando o ambiente e o agente\n",
    "ambiente = AspiradorEnv()\n",
    "agente = AgenteSimples()\n",
    "\n",
    "num_episodios = 5\n",
    "\n",
    "for episodio in range(num_episodios):\n",
    "    estado = ambiente.reset()\n",
    "    done = False\n",
    "    passos = 0\n",
    "\n",
    "    print(f\"\\nEpisódio {episodio + 1}:\")\n",
    "    while not done:\n",
    "        ambiente.render()\n",
    "        acao = agente.escolher_acao(estado)\n",
    "        estado, recompensa, done, _ = ambiente.step(acao)\n",
    "        passos += 1\n",
    "        print(f\"Ação: {acao}, Recompensa: {recompensa}\")\n",
    "\n",
    "    print(f\"Episódio concluído em {passos} passos!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
